{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Each team may have 1~4 students. Top 10% teams worldwide as of 11:59pm on May 11, 2022 will get A in this class.\nFeature engineering: create new features from the raw data.\n\nSupervised learning models: Choose 2 supervised learning models from W3, W4, W5.\n\nAdvanced models: choose 1 from XGBoost W12 or Neural Network W13 or Deep learning W14 to build your supervised learning models.\n\nModel evaluation: For each of the supervised learning models, evaluate the model using the techniques from W10\n\nIf data size is too big and your model is too slow, feel free to choose small set for your project.\n\nYour jupyter submission should be in an article quality.\n\nDo NOT print huge data set in the notebook. Use head(). Use plotting to visualize your analysis and results. Use markdown to write your comments.\n\nIf you are not in the top 10% teams worldwide, your score is based on completeness on every step as described above.\n\nSubmit in HTML and ipynb format on canvas.<font/>","metadata":{}},{"cell_type":"markdown","source":"<font size='5'>Group Members:<font/>\n    <br>\n<font size='5'>i)Aditya Maniar(am3326) <font/>\n    <br>\n    <font size='5'>                       ii)Tanishq Dwivedi(td43) <font/>","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport nltk\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport numpy as np \nimport re\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk import ngrams\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk import word_tokenize\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer ,CountVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report\nfrom tensorflow import keras\nfrom keras.models import Sequential,Model\nfrom keras.layers import Flatten,Dense,LSTM,Dropout,BatchNormalization,Bidirectional,Embedding, Conv1D,MaxPooling1D, GlobalMaxPooling1D\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.metrics import confusion_matrix\n\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('wordnet') ","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:34:15.315373Z","iopub.execute_input":"2022-05-12T03:34:15.315674Z","iopub.status.idle":"2022-05-12T03:34:15.333164Z","shell.execute_reply.started":"2022-05-12T03:34:15.315643Z","shell.execute_reply":"2022-05-12T03:34:15.332291Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"train_data=pd.read_csv('../input/nlpgettingstarted/train.csv')\ntest_data=pd.read_csv('../input/nlpgettingstarted/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:30.261509Z","iopub.execute_input":"2022-05-12T03:13:30.261829Z","iopub.status.idle":"2022-05-12T03:13:30.345436Z","shell.execute_reply.started":"2022-05-12T03:13:30.261770Z","shell.execute_reply":"2022-05-12T03:13:30.344209Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:32.737363Z","iopub.execute_input":"2022-05-12T03:13:32.738174Z","iopub.status.idle":"2022-05-12T03:13:32.765557Z","shell.execute_reply.started":"2022-05-12T03:13:32.738132Z","shell.execute_reply":"2022-05-12T03:13:32.764625Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:33.271382Z","iopub.execute_input":"2022-05-12T03:13:33.271666Z","iopub.status.idle":"2022-05-12T03:13:33.294017Z","shell.execute_reply.started":"2022-05-12T03:13:33.271634Z","shell.execute_reply":"2022-05-12T03:13:33.293172Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:33.922704Z","iopub.execute_input":"2022-05-12T03:13:33.923008Z","iopub.status.idle":"2022-05-12T03:13:33.938709Z","shell.execute_reply.started":"2022-05-12T03:13:33.922977Z","shell.execute_reply":"2022-05-12T03:13:33.937492Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print('Number of Unique Keywords : ',len(train_data.keyword.unique()))\ntrain_data.keyword.value_counts(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:34.634439Z","iopub.execute_input":"2022-05-12T03:13:34.635287Z","iopub.status.idle":"2022-05-12T03:13:34.657728Z","shell.execute_reply.started":"2022-05-12T03:13:34.635224Z","shell.execute_reply":"2022-05-12T03:13:34.656812Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data.drop('id',inplace=True,axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:35.399335Z","iopub.execute_input":"2022-05-12T03:13:35.399840Z","iopub.status.idle":"2022-05-12T03:13:35.406249Z","shell.execute_reply.started":"2022-05-12T03:13:35.399794Z","shell.execute_reply":"2022-05-12T03:13:35.405213Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_data.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:37.227096Z","iopub.execute_input":"2022-05-12T03:13:37.227386Z","iopub.status.idle":"2022-05-12T03:13:37.234961Z","shell.execute_reply.started":"2022-05-12T03:13:37.227355Z","shell.execute_reply":"2022-05-12T03:13:37.234135Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"6\">Preprocessing of text data</font>","metadata":{}},{"cell_type":"code","source":"#convert tweets to lower_case\ndef lower_case(text):\n    text = [' '.join(tx.lower() for tx in word.split()) for word in text]\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:39.693672Z","iopub.execute_input":"2022-05-12T03:13:39.694267Z","iopub.status.idle":"2022-05-12T03:13:39.699471Z","shell.execute_reply.started":"2022-05-12T03:13:39.694231Z","shell.execute_reply":"2022-05-12T03:13:39.698372Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Make A List Of All Words \nwords=[]\nfor i in train_data.text:\n    words.extend(i.split())\nprint('Unique words:',len(set(words)))\nprint('total words:',len(words))","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:40.261520Z","iopub.execute_input":"2022-05-12T03:13:40.261847Z","iopub.status.idle":"2022-05-12T03:13:40.297646Z","shell.execute_reply.started":"2022-05-12T03:13:40.261811Z","shell.execute_reply":"2022-05-12T03:13:40.296684Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# remove #retweet from tweets \ndef retweets(text):\n    tweets = [' '.join([re.sub('^@(\\w)+',' ',tw) for tw in tweet.split()]) for tweet in text]  \n    return tweets","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:40.697084Z","iopub.execute_input":"2022-05-12T03:13:40.697964Z","iopub.status.idle":"2022-05-12T03:13:40.705245Z","shell.execute_reply.started":"2022-05-12T03:13:40.697902Z","shell.execute_reply":"2022-05-12T03:13:40.704202Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#remove url's from tweets\ndef drop_url(text):\n    url = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n    tweets = [' '.join([re.sub(url,' ',tw) for tw in tweet.split()]) for tweet in text]  \n    return tweets","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:41.137969Z","iopub.execute_input":"2022-05-12T03:13:41.138911Z","iopub.status.idle":"2022-05-12T03:13:41.145732Z","shell.execute_reply.started":"2022-05-12T03:13:41.138852Z","shell.execute_reply":"2022-05-12T03:13:41.144861Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#lemmatizing \ndef lemmatize(tweets):\n    lemmatizer = WordNetLemmatizer() \n    tweets = [' '.join(lemmatizer.lemmatize(word) for word in word_tokenize(tweet)) for tweet in tweets]\n    return tweets\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:41.566839Z","iopub.execute_input":"2022-05-12T03:13:41.567971Z","iopub.status.idle":"2022-05-12T03:13:41.574154Z","shell.execute_reply.started":"2022-05-12T03:13:41.567909Z","shell.execute_reply":"2022-05-12T03:13:41.572957Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#removing stop words\ndef stop_words(tweets):\n    stop_words = set(stopwords.words('english'))\n    tweets = [' '.join(word for word in word_tokenize(tweet) if word not in stop_words) for tweet in tweets]\n    return tweets","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:41.976758Z","iopub.execute_input":"2022-05-12T03:13:41.977545Z","iopub.status.idle":"2022-05-12T03:13:41.982709Z","shell.execute_reply.started":"2022-05-12T03:13:41.977506Z","shell.execute_reply":"2022-05-12T03:13:41.981727Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#final cleaning of tweets\ndef final_cleaning(tweets):\n    tweets = [\" \".join(word_tokenize(tweet)) for tweet in tweets]\n    return tweets","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:42.401628Z","iopub.execute_input":"2022-05-12T03:13:42.402150Z","iopub.status.idle":"2022-05-12T03:13:42.407866Z","shell.execute_reply.started":"2022-05-12T03:13:42.402100Z","shell.execute_reply":"2022-05-12T03:13:42.406070Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def vectorizing(number,corpus):\n    count_vec = CountVectorizer(ngram_range=(number, number)).fit(corpus)\n    bag_of_words = count_vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in count_vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:42.823603Z","iopub.execute_input":"2022-05-12T03:13:42.824256Z","iopub.status.idle":"2022-05-12T03:13:42.831236Z","shell.execute_reply.started":"2022-05-12T03:13:42.824218Z","shell.execute_reply":"2022-05-12T03:13:42.829929Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# get final data according to target variable ie. 0 and 1 \ndef final_data(target):\n    clean_data = lower_case(train_data[train_data[\"target\"] == target][\"text\"])\n    clean_data = retweets(clean_data)\n    clean_data = drop_url(clean_data)\n    clean_data = lemmatize(clean_data)\n    clean_data = stop_words(clean_data)\n    clean_data = final_cleaning(clean_data)\n    return clean_data","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:43.203624Z","iopub.execute_input":"2022-05-12T03:13:43.204184Z","iopub.status.idle":"2022-05-12T03:13:43.210106Z","shell.execute_reply.started":"2022-05-12T03:13:43.204146Z","shell.execute_reply":"2022-05-12T03:13:43.208630Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"<font size='6'>Using Count Vectorizer to find continuous sequences( in this case '1') of words or symbols or tokens in the clean text and then printing the frequency of each word.<font/>\n    <br>\n    ","metadata":{}},{"cell_type":"code","source":"#for negative reactions\nvectorizing(1,final_data(0))[:50]","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:44.489370Z","iopub.execute_input":"2022-05-12T03:13:44.489650Z","iopub.status.idle":"2022-05-12T03:13:52.102983Z","shell.execute_reply.started":"2022-05-12T03:13:44.489620Z","shell.execute_reply":"2022-05-12T03:13:52.102180Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#for positive reactions\nvectorizing(1,final_data(1))[:50]","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:13:52.104530Z","iopub.execute_input":"2022-05-12T03:13:52.104923Z","iopub.status.idle":"2022-05-12T03:13:55.247478Z","shell.execute_reply.started":"2022-05-12T03:13:52.104884Z","shell.execute_reply":"2022-05-12T03:13:55.246675Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"6\">Next we will create a pipeline with all the above functions for smooth preprocessing of the train and test data.</font> ","metadata":{}},{"cell_type":"code","source":"pipe1 = FunctionTransformer(lower_case)\npipe2 = FunctionTransformer(retweets)\npipe3 = FunctionTransformer(drop_url)\npipe4 = FunctionTransformer(lemmatize)\npipe5 = FunctionTransformer(final_cleaning)\npipe6 = FunctionTransformer(stop_words)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:16:45.658735Z","iopub.execute_input":"2022-05-12T03:16:45.659466Z","iopub.status.idle":"2022-05-12T03:16:45.665865Z","shell.execute_reply.started":"2022-05-12T03:16:45.659424Z","shell.execute_reply":"2022-05-12T03:16:45.664931Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#This function will feed the pipeline to the different supervised models for prediction and classification report.  \ndef preproc_pipeline(pipe):\n    pipeline = Pipeline(pipe)\n    \n    x =train_data.text.copy()\n    y =train_data.target.copy()\n    X_train ,X_test ,y_train,y_test =train_test_split(x,y,test_size=0.2,random_state=42)\n    \n    pipeline.fit(X_train,y_train)\n    target_preds =pipeline.predict(X_test)\n    print('Confusion Matrix: ')\n    print(confusion_matrix(y_test, target_preds))\n    print(classification_report(y_test,target_preds))\n    return pipeline","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:24:05.782605Z","iopub.execute_input":"2022-05-12T03:24:05.782912Z","iopub.status.idle":"2022-05-12T03:24:05.792121Z","shell.execute_reply.started":"2022-05-12T03:24:05.782880Z","shell.execute_reply":"2022-05-12T03:24:05.790297Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"6\">Model 1: Using Support Vector Classification</font> ","metadata":{}},{"cell_type":"code","source":"SVC_model = SVC()\npipeline = [('lower',pipe1),('retweet',pipe2),('urls',pipe3),('lematize',pipe4),('spacs',pipe5),('tf_idf',TfidfVectorizer()),('model',SVC_model)]\npipeline_svc = preproc_pipeline(pipeline)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:24:07.276691Z","iopub.execute_input":"2022-05-12T03:24:07.277363Z","iopub.status.idle":"2022-05-12T03:24:20.729086Z","shell.execute_reply.started":"2022-05-12T03:24:07.277323Z","shell.execute_reply":"2022-05-12T03:24:20.727831Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"<font size='6' color='red'>Accuracy of SVC model is 82%.  <font/>\n    <br>\n    <br>","metadata":{}},{"cell_type":"markdown","source":"<font size='6'>Model 2: Using Logistic Regression  <font/>","metadata":{}},{"cell_type":"code","source":"logistic_reg=LogisticRegression()\npipeline = [('lower',pipe1),('retweet',pipe2),('urls',pipe3),('lematize',pipe4),('spacs',pipe5),('tf_idf',TfidfVectorizer()),('model',logistic_reg)]\npipeline_logistic_reg = preproc_pipeline(pipeline)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:24:32.158474Z","iopub.execute_input":"2022-05-12T03:24:32.158833Z","iopub.status.idle":"2022-05-12T03:24:38.225278Z","shell.execute_reply.started":"2022-05-12T03:24:32.158776Z","shell.execute_reply":"2022-05-12T03:24:38.224172Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"<font size='6' color='red'>Accuracy of Logistic Regression model is 81%. <font/>","metadata":{}},{"cell_type":"markdown","source":"<br>\n<font size='6'>Using a CNN model<font/>","metadata":{}},{"cell_type":"code","source":"x = train_data.text.copy()\nx = lower_case(x)\nx = retweets(x)\nx = drop_url(x)\nx = lemmatize(x)\nx = final_cleaning(x) \ny =train_data.target.copy()\n\ntokenize = Tokenizer()\ntokenize.fit_on_texts(x)\nx = tokenize.texts_to_sequences(x)\nprint(len(tokenize.word_index)+1)\nvocab_length =len(tokenize.index_word)+1\nx = pad_sequences(x,maxlen=np.max(vocab_length))\nX_train ,X_test ,y_train,y_test =train_test_split(x,y,test_size=0.2,random_state=42)\nprint(x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:24:44.624757Z","iopub.execute_input":"2022-05-12T03:24:44.625408Z","iopub.status.idle":"2022-05-12T03:24:51.321087Z","shell.execute_reply.started":"2022-05-12T03:24:44.625367Z","shell.execute_reply":"2022-05-12T03:24:51.320167Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model =Sequential()\n\nmodel.add(Embedding(input_length=vocab_length,output_dim=32,input_dim=vocab_length))\n\nmodel.add(BatchNormalization())\n\nmodel.add(GlobalMaxPooling1D())\n\nmodel.add(Dropout(0.7))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(1,activation='sigmoid'))\n\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=0.001,\n    decay_steps=1000,\n    decay_rate=0.9)\nes = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto',patience=3,restore_best_weights=True)\nmodel.compile(optimizer=keras.optimizers.Adam(learning_rate=lr_schedule)\n              ,loss='binary_crossentropy',metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:25:06.731407Z","iopub.execute_input":"2022-05-12T03:25:06.731700Z","iopub.status.idle":"2022-05-12T03:25:10.389814Z","shell.execute_reply.started":"2022-05-12T03:25:06.731670Z","shell.execute_reply":"2022-05-12T03:25:10.388993Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train,y_train,\n                    epochs=15,verbose=1,validation_data = (X_test,y_test),callbacks=es)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:25:26.380898Z","iopub.execute_input":"2022-05-12T03:25:26.381191Z","iopub.status.idle":"2022-05-12T03:26:30.672729Z","shell.execute_reply.started":"2022-05-12T03:25:26.381160Z","shell.execute_reply":"2022-05-12T03:26:30.671920Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model.summary()\nloss, acc = model.evaluate(X_test, y_test, verbose=0)\nprint('Test Accuracy: %f' % (acc*100))","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:26:39.466119Z","iopub.execute_input":"2022-05-12T03:26:39.466427Z","iopub.status.idle":"2022-05-12T03:26:40.060912Z","shell.execute_reply.started":"2022-05-12T03:26:39.466384Z","shell.execute_reply":"2022-05-12T03:26:40.059803Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"cnn_preds=model.predict(X_test)\nfor i in range(0,len(cnn_preds)):\n    if(cnn_preds[i]>0.5):\n        cnn_preds[i]=1\n    else:\n        cnn_preds[i]=0\nprint('Confusion Matrix: ')\nprint(confusion_matrix(y_test, cnn_preds))\nprint(classification_report(y_test,cnn_preds))","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:30:09.055132Z","iopub.execute_input":"2022-05-12T03:30:09.055533Z","iopub.status.idle":"2022-05-12T03:30:09.836608Z","shell.execute_reply.started":"2022-05-12T03:30:09.055495Z","shell.execute_reply":"2022-05-12T03:30:09.835246Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"<font size='6'>Prediction using CNN model<font/>","metadata":{}},{"cell_type":"code","source":"a = test_data.text.copy()\na = lower_case(a)\na = retweets(a)\na = drop_url(a)\na = lemmatize(a)\na = final_cleaning(a) \n\ntokenize = Tokenizer()\ntokenize.fit_on_texts(a)\na = tokenize.texts_to_sequences(a)\nprint(len(tokenize.word_index)+1)\nvocab_length =len(tokenize.index_word)+1\na = pad_sequences(a,maxlen=np.max(vocab_length))","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:30:30.136433Z","iopub.execute_input":"2022-05-12T03:30:30.136729Z","iopub.status.idle":"2022-05-12T03:30:32.575562Z","shell.execute_reply.started":"2022-05-12T03:30:30.136696Z","shell.execute_reply":"2022-05-12T03:30:32.574753Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"final_preds=model.predict(a)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:30:35.295294Z","iopub.execute_input":"2022-05-12T03:30:35.296063Z","iopub.status.idle":"2022-05-12T03:30:36.107880Z","shell.execute_reply.started":"2022-05-12T03:30:35.296019Z","shell.execute_reply":"2022-05-12T03:30:36.107043Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"for i in range(0,len(final_preds)):\n    if(final_preds[i]>0.5):\n        final_preds[i]=1\n    else:\n        final_preds[i]=0","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:30:41.335880Z","iopub.execute_input":"2022-05-12T03:30:41.336585Z","iopub.status.idle":"2022-05-12T03:30:41.353234Z","shell.execute_reply.started":"2022-05-12T03:30:41.336540Z","shell.execute_reply":"2022-05-12T03:30:41.351999Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"final_preds=np.array(final_preds,int)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:30:43.679378Z","iopub.execute_input":"2022-05-12T03:30:43.679649Z","iopub.status.idle":"2022-05-12T03:30:43.684468Z","shell.execute_reply.started":"2022-05-12T03:30:43.679619Z","shell.execute_reply":"2022-05-12T03:30:43.683650Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"sample1 = pd.read_csv('../input/nlpgettingstarted/sample_submission.csv')\nsample1['target']=final_preds\nsample1.to_csv('submission1.csv',index = False)\nsample1","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:22:43.150317Z","iopub.execute_input":"2022-05-11T21:22:43.150748Z","iopub.status.idle":"2022-05-11T21:22:43.179158Z","shell.execute_reply.started":"2022-05-11T21:22:43.150709Z","shell.execute_reply":"2022-05-11T21:22:43.178477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### <font size='6'>Prediction using SVC model<font/>","metadata":{}},{"cell_type":"code","source":"test_pred=test_data.text\ntest_prediction = pipeline_svc.predict(test_pred)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T03:31:18.023615Z","iopub.execute_input":"2022-05-12T03:31:18.023880Z","iopub.status.idle":"2022-05-12T03:31:23.251751Z","shell.execute_reply.started":"2022-05-12T03:31:18.023852Z","shell.execute_reply":"2022-05-12T03:31:23.250798Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"sample2 = pd.read_csv('../input/nlpgettingstarted/sample_submission.csv')\nsample2['target']=test_prediction\nsample2.to_csv('submission2.csv',index = False)\nsample2","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:24:39.537098Z","iopub.execute_input":"2022-05-11T21:24:39.537361Z","iopub.status.idle":"2022-05-11T21:24:39.56047Z","shell.execute_reply.started":"2022-05-11T21:24:39.537331Z","shell.execute_reply":"2022-05-11T21:24:39.559772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"<font size='6'>Using BertTokenizer and Bert Model for Prediction","metadata":{}},{"cell_type":"code","source":"import transformers\nfrom transformers import BertTokenizer\nfrom transformers import TFBertModel\nimport random,os\nimport warnings\n\nwarnings.filterwarnings('ignore')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:27:50.597424Z","iopub.execute_input":"2022-05-11T21:27:50.597701Z","iopub.status.idle":"2022-05-11T21:27:53.204399Z","shell.execute_reply.started":"2022-05-11T21:27:50.597671Z","shell.execute_reply":"2022-05-11T21:27:53.203658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 2022\ndef seed_everything(seed=SEED):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    \nseed_everything()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased\", do_lower_case=True)\ndef bert_encode(data,maximum_length) :\n    input_ids = []\n    attention_masks = []\n    \n    for i in range(len(data.text)):\n        encoded = tokenizer.encode_plus(\n\n        data.text[i],\n        add_special_tokens=True,\n        max_length=maximum_length,\n        pad_to_max_length=True,\n\n        return_attention_mask=True,\n\n        )\n\n        input_ids.append(encoded['input_ids'])\n        attention_masks.append(encoded['attention_mask'])\n\n    return np.array(input_ids),np.array(attention_masks)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:25:44.040032Z","iopub.execute_input":"2022-05-11T21:25:44.040926Z","iopub.status.idle":"2022-05-11T21:25:45.783881Z","shell.execute_reply.started":"2022-05-11T21:25:44.04087Z","shell.execute_reply":"2022-05-11T21:25:45.783115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input_ids,train_attention_masks = bert_encode(train_data,60)\ntest_input_ids,test_attention_masks = bert_encode(test_data,60)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:25:55.659937Z","iopub.execute_input":"2022-05-11T21:25:55.660614Z","iopub.status.idle":"2022-05-11T21:26:04.472362Z","shell.execute_reply.started":"2022-05-11T21:25:55.660576Z","shell.execute_reply":"2022-05-11T21:26:04.471583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(bert_model):\n    input_ids = tf.keras.Input(shape=(60,),dtype='int32')\n    attention_masks = tf.keras.Input(shape=(60,),dtype='int32')\n\n    output = bert_model([input_ids,attention_masks])\n    output = output[1]\n    output = tf.keras.layers.Dense(32,activation='relu')(output)\n    output = tf.keras.layers.Dropout(0.2)(output)\n\n    output = tf.keras.layers.Dense(1,activation='sigmoid')(output)\n    model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n    model.compile(tensorflow.keras.optimizers.Adam(lr=6e-6), loss='binary_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:26:08.289141Z","iopub.execute_input":"2022-05-11T21:26:08.289813Z","iopub.status.idle":"2022-05-11T21:26:08.296433Z","shell.execute_reply.started":"2022-05-11T21:26:08.289774Z","shell.execute_reply":"2022-05-11T21:26:08.295607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_model = TFBertModel.from_pretrained(\"bert-large-uncased\")\n\nmodel = create_model(bert_model)\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    [train_input_ids,train_attention_masks],\n    train_data['target'],\n    validation_split=0.2,\n    epochs=2,\n    batch_size=10)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T20:44:06.152116Z","iopub.execute_input":"2022-05-11T20:44:06.15245Z","iopub.status.idle":"2022-05-11T20:44:06.226396Z","shell.execute_reply.started":"2022-05-11T20:44:06.152363Z","shell.execute_reply":"2022-05-11T20:44:06.225457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_test = model.predict([test_input_ids,test_attention_masks])\n\nsub = pd.read_csv('../input/nlpgettingstarted/sample_submission.csv')\nsub['target'] = np.round(pred_test).astype(int)\nsub.to_csv('final_submission',index=False)\nsub.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size='6'> We used SVC, Logistic Regression, CN, and a pretrained Model (Bert Model) for prediction. Since Bert Model is giving maximum accuracy while prediciting, we will use the predictions of the Bert Model for the Kaggle Competietion.<font/>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}